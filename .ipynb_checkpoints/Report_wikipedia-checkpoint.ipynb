{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do not spend too much time trying to get very tiny metrics improvement. Once you have a model with a correct predictive power, you should better spend time explaining your data cleaning & preparation pipeline as well as explanations & visualizations of the results.\n",
    "\n",
    "The goal is to see your fit with our company culture & engineering needs, spending 50h on an over-complicated approach will not give you bonus points compared to a simple, yet effective, to-the-point solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this project you will be working on Wikipedia articles. \n",
    "   \n",
    "The goal of this project is to develop :\n",
    "\n",
    "* A scraper that is able to retrieve wikipedia articles from 10 different categories of your choice (i.e. Sports, Politics, etc...)\n",
    "* A model that is able to **classify previously unseen Wikipedia articles** based on the categories you extracted earlier. \n",
    "\n",
    "Feel free to use any available library you would need, but beware of re-using someone else's code without mentionning it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deliverable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The end-goal is to deliver us a zip file containing:\n",
    "* This report filled with your approach, in the form of an **iPython Notebook**.\n",
    "* A **5-10 slides PDF file**, containing a technical presentation covering the important aspects of your work\n",
    "* A Dockerfile which defines a container for the project. The container should handle everything (download the data, run the code, etc...). When running the container it should expose the jupyter notebook on one port and expose a Flask API on another one. The Flask app contains two endpoints:\n",
    "  - One for scraping the data and training the model\n",
    "  - One for querying the last trained model with an article of our choice in the dataset\n",
    "* A README.md which should contain the commands to build and run the docker container, as well as how to perform the queries to the API. \n",
    "* Any necessary .py, .sh or other files needed to run your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import random\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import classification_report\n",
    "import transformers\n",
    "from transformers import AutoModel, BertTokenizerFast, BertForSequenceClassification, AdamW, BertConfig\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "import time\n",
    "import datetime\n",
    "from sklearn.metrics import classification_report\n",
    "import seaborn as sns\n",
    "from queue import Queue, Empty\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(29)\n",
    "np.random.seed(29)\n",
    "torch.manual_seed(29)\n",
    "torch.cuda.manual_seed_all(29)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation & Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The title is probably not needed because I will use the content for the classification but maybe in a future implementation it could be used to improve the classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=[\"title\", \"content\",\"category\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape data\n",
    "This approach is based on :\n",
    "* https://levelup.gitconnected.com/two-simple-ways-to-scrape-text-from-wikipedia-in-python-9ce07426579b\n",
    "* https://www.freecodecamp.org/news/scraping-wikipedia-articles-with-python/\n",
    "\n",
    "Implementation to scrape data from wikipedia page (title and content). The script start from a given page and it continues recursively to scrape pages that are related to the initial one (links). The script ends when it reaches a given number of pages (e.g. 10)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get wikipedia articles given seed urls (it can work with a single seed or multi seeds). This approach is very simple and can be extended with more inspections to the links (e.g. no images, no category pages, etc.). I did not use a specific library because for this task I think it is enough to have a simple approach which can do the minimum (I did want to use time to learn a new library to do this simple scraping) but in a future implementation it could be good to use https://scrapy.org/ a open source and collaborative framework for extracting the data you need from websites. \n",
    "\n",
    "At the moment this scraping is quite slow but the speed is something that can be solved in a second step e.g. with multi threading or using the wikipedia API (https://pypi.org/project/wikipedia/).\n",
    "\n",
    "Moreover this implementation has many overhead e.g. an article could be processed multiple times. To improve this a big list should be created and each page should be confronted with every category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single threading scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links(urls,category,num,max_num):\n",
    "    # use global dataframe\n",
    "    global df\n",
    "    \n",
    "    while len(urls)>0 and num <= max_num:\n",
    "    \n",
    "        # get random link from urls (in this way we are not going deeper and deeper but randomly)\n",
    "        url = random.choice(urls)\n",
    "        \n",
    "        response = requests.get(url=url)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        regex = re.compile(r'/wiki/.+')\n",
    "\n",
    "        # Get article categories\n",
    "        categories = soup.find(id=\"mw-normal-catlinks\")\n",
    "\n",
    "        # Check if page contains categories (e.g. an image page does not have this information)\n",
    "        if categories is None:\n",
    "            continue\n",
    "        \n",
    "        categories = categories.select('li a')\n",
    "        # Continue only if articles contains the given category\n",
    "        if any(category in cat.text.lower() for cat in categories):\n",
    "            \n",
    "            # Get article title\n",
    "            title = soup.find(id=\"firstHeading\").text\n",
    "\n",
    "            # Get article content\n",
    "            text = ''\n",
    "            for paragraph in soup.find_all('p'):\n",
    "                text += paragraph.text\n",
    "                \n",
    "            # Drop footnote superscripts in brackets and Replace â€˜\\nâ€™ (a new line) with â€˜â€™ (an empty string) \n",
    "            text = re.sub(r'\\[.*?\\]+', '', text)\n",
    "            text = text.replace('\\n', '')\n",
    "\n",
    "            # Add article to dataframe\n",
    "            df = df.append({\n",
    "                \"title\": title,\n",
    "                \"content\": text,\n",
    "                \"category\": category\n",
    "            },ignore_index=True)\n",
    "            \n",
    "            num += 1\n",
    "            # print(category+\" \"+title)\n",
    "\n",
    "            # Scrape other pages from links\n",
    "            # Get all the links\n",
    "            links = soup.find(id=\"bodyContent\").find_all(\"a\",{'href': True})\n",
    "            \n",
    "            \n",
    "            for link in links:\n",
    "                # Only interested in other wiki articles (remove external links and images)\n",
    "                if re.match(regex,link.get('href')): \n",
    "                    urls.append(\"https://en.wikipedia.org\" + link.get('href'))\n",
    "                    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t0 = time.time()\n",
    "# get_links([\"https://en.wikipedia.org/wiki/Sport\"],\"sport\",0,10) \n",
    "# print(time.time()-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_links([\"https://en.wikipedia.org/wiki/Economy\"],\"economy\",0,10)\n",
    "#get_links([\"https://en.wikipedia.org/wiki/Engineering\"],\"engineering\",0,10)\n",
    "#get_links([\"https://en.wikipedia.org/wiki/History\"],\"history\",0,10)\n",
    "#get_links([\"https://en.wikipedia.org/wiki/Philosophy\"],\"philosophy\",0,10)\n",
    "#get_links([\"https://en.wikipedia.org/wiki/Politics\"],\"politics\",0,10)\n",
    "#get_links([\"https://en.wikipedia.org/wiki/Religion\"],\"religion\",0,10)\n",
    "#get_links([\"https://en.wikipedia.org/wiki/Universe\"],\"universe\",0,10)\n",
    "#get_links([\"https://en.wikipedia.org/wiki/Law\"],\"law\",0,10)\n",
    "#get_links([\"https://en.wikipedia.org/wiki/Culture\"],\"culture\",0,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multithreading version scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MultiThread version (is not my best piece of code but it works and it is much faster. The threadpoolexecutor shotdown and the counting mechanism should be improved). \n",
    "\n",
    "Single thread for 10 articles: 11.07 secs\n",
    "Multi threads for 10 articles: 2.80 secs\n",
    "\n",
    "Based on https://edmundmartin.com/multi-threaded-crawler-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiThreadScraper:\n",
    "    \n",
    "    def __init__(self,base_urls,category,max_num):\n",
    "        self.category = category\n",
    "        self.max_num = max_num\n",
    "        self.pool = ThreadPoolExecutor(max_workers=10)\n",
    "        self.scraped_pages = set([])\n",
    "        self.to_crawl = Queue()\n",
    "        # add base urls\n",
    "        for url in base_urls:\n",
    "            self.to_crawl.put(url)\n",
    "        self.num = 0\n",
    "        \n",
    "    def parse_links(self,html):\n",
    "        global df\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        regex = re.compile(r'/wiki/.+')\n",
    "\n",
    "        # Get article categories\n",
    "        categories = soup.find(id=\"mw-normal-catlinks\")\n",
    "\n",
    "        # Check if page contains categories (e.g. an image page does not have this information)\n",
    "        if categories is None:\n",
    "            return\n",
    "        \n",
    "        categories = categories.select('li a')\n",
    "        # Continue only if articles contains the given category\n",
    "        if any(self.category in cat.text.lower() for cat in categories):\n",
    "            \n",
    "            # Get article title\n",
    "            title = soup.find(id=\"firstHeading\").text\n",
    "\n",
    "            # Get article content\n",
    "            text = ''\n",
    "            for paragraph in soup.find_all('p'):\n",
    "                text += paragraph.text\n",
    "                \n",
    "            # Drop footnote superscripts in brackets and Replace â€˜\\nâ€™ (a new line) with â€˜â€™ (an empty string) \n",
    "            text = re.sub(r'\\[.*?\\]+', '', text)\n",
    "            text = text.replace('\\n', '')\n",
    "            \n",
    "            self.num += 1\n",
    "            \n",
    "            # Add article to dataframe\n",
    "            df = df.append({\n",
    "                \"title\": title,\n",
    "                \"content\": text,\n",
    "                \"category\": self.category\n",
    "            },ignore_index=True)\n",
    "            \n",
    "            \n",
    "            #print(self.category+\" \"+title)\n",
    "\n",
    "            # Scrape other pages from links\n",
    "            # Get all the links\n",
    "            links = soup.find(id=\"bodyContent\").find_all(\"a\",{'href': True})\n",
    "            \n",
    "            \n",
    "            for link in links:\n",
    "                # Only interested in other wiki articles (remove external links and images)\n",
    "                if re.match(regex,link.get('href')): \n",
    "                    self.to_crawl.put(\"https://en.wikipedia.org\" + link.get('href'))\n",
    "                    \n",
    "    def post_scrape_callback(self,res):\n",
    "        result = res.result()\n",
    "        if result and result.status_code == 200 and self.num<self.max_num:\n",
    "            self.parse_links(result.text)\n",
    "            \n",
    "    def scrape_page(self,url):\n",
    "        try:\n",
    "            res = requests.get(url, timeout=(3, 30))\n",
    "            return res\n",
    "        except requests.RequestException:\n",
    "            return\n",
    "        \n",
    "    def run_scraper(self):\n",
    "        while True:\n",
    "            try:\n",
    "                target_url = self.to_crawl.get(timeout=10)\n",
    "                # return if reached target number of articles\n",
    "                if self.num>self.max_num:\n",
    "                    self.pool.shutdown(wait=False)\n",
    "                    return\n",
    "                if target_url not in self.scraped_pages:\n",
    "                    # print(\"Scraping URL: {}\".format(target_url))\n",
    "                    self.scraped_pages.add(target_url)\n",
    "                    job = self.pool.submit(self.scrape_page, target_url)\n",
    "                    job.add_done_callback(self.post_scrape_callback)\n",
    "            except Empty:\n",
    "                return\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.94071102142334\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "s = MultiThreadScraper([\"https://en.wikipedia.org/wiki/Sport\"],\"sport\",50)\n",
    "s.run_scraper()\n",
    "print(time.time()-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = MultiThreadScraper([\"https://en.wikipedia.org/wiki/Economy\"],\"economy\",50)\n",
    "s.run_scraper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = MultiThreadScraper([\"https://en.wikipedia.org/wiki/Engineering\"],\"engineering\",50)\n",
    "s.run_scraper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = MultiThreadScraper([\"https://en.wikipedia.org/wiki/History\"],\"history\",50)\n",
    "s.run_scraper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = MultiThreadScraper([\"https://en.wikipedia.org/wiki/Philosophy\"],\"philosophy\",50)\n",
    "s.run_scraper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = MultiThreadScraper([\"https://en.wikipedia.org/wiki/Politics\"],\"politics\",50)\n",
    "s.run_scraper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = MultiThreadScraper([\"https://en.wikipedia.org/wiki/Religion\"],\"religion\",50)\n",
    "s.run_scraper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = MultiThreadScraper([\"https://en.wikipedia.org/wiki/Food\"],\"food\",50)\n",
    "s.run_scraper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = MultiThreadScraper([\"https://en.wikipedia.org/wiki/Law\"],\"law\",50)\n",
    "s.run_scraper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = MultiThreadScraper([\"https://en.wikipedia.org/wiki/Culture\"],\"culture\",50)\n",
    "s.run_scraper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!!!!!! It still take quite a long time to complete the scraping... on Google Colab it takes around 20 minutes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save dataframe (for later use if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(\"./dataframe.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_pickle(\"./dataframe.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This approach is based on :\n",
    "* https://github.com/ArmandDS/bert_for_long_text/blob/master/final_bert_long_docs.ipynb\n",
    "\n",
    "Clean and analyse data before training the choosen model for text classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.content.apply(lambda x:len(x.split())).plot(kind='hist',bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Articles with more than 2000 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.content[df.content.apply(lambda x:len(x.split()) > 2000)].apply(lambda x:len(x.split())).plot(kind='hist',bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Articles with less than 2000 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.content[df.content.apply(lambda x:len(x.split()) < 2000)].apply(lambda x:len(x.split())).plot(kind='hist',bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of articles below and above 500 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.content[df.content.apply(lambda x:len(x.split()) < 500)].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "386"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.content[df.content.apply(lambda x:len(x.split()) > 500)].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.810344827586206"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(78/df.content.count())*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83.1896551724138"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(386/df.content.count())*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Info about articles length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>464.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3452.566810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3327.294736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>863.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2267.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5159.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15209.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                len\n",
       "count    464.000000\n",
       "mean    3452.566810\n",
       "std     3327.294736\n",
       "min        0.000000\n",
       "25%      863.250000\n",
       "50%     2267.000000\n",
       "75%     5159.500000\n",
       "max    15209.000000"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['len'] = df.content.apply(lambda x:len(x.split()))\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The articles are quite long in general (up to 12000). The mean is 3452 words. The 83% are above 500 words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep only content and category and rename them to text and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['content','category']].rename(columns = {\"content\":\"text\",\"category\":\"label\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyse size of the different categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['label'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty much all the categories reach the target number of articles (50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode label to integer values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sport includes all forms of competitive physic...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A team sport includes any sport where individu...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In games and sports, a tiebreaker or tiebreak ...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A champion (from the late Latin campio) is the...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A sports league is a group of sports teams tha...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  Sport includes all forms of competitive physic...      9\n",
       "1  A team sport includes any sport where individu...      9\n",
       "2  In games and sports, a tiebreaker or tiebreak ...      9\n",
       "3  A champion (from the late Latin campio) is the...      9\n",
       "4  A sports league is a group of sports teams tha...      9"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "df['label'] = label_encoder.fit_transform(df['label'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if there are 10 classes as given in the assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(np.unique(df['label']))==10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional cleaning to remove apostrophes and tabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_txt(text):\n",
    "  text = re.sub(\"'\", \"\",text)\n",
    "  text=re.sub(\"(\\\\W)+\",\" \",text)    \n",
    "  return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sport includes all forms of competitive physic...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A team sport includes any sport where individu...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In games and sports a tiebreaker or tiebreak i...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A champion from the late Latin campio is the v...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A sports league is a group of sports teams tha...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  Sport includes all forms of competitive physic...      9\n",
       "1  A team sport includes any sport where individu...      9\n",
       "2  In games and sports a tiebreaker or tiebreak i...      9\n",
       "3  A champion from the late Latin campio is the v...      9\n",
       "4  A sports league is a group of sports teams tha...      9"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text']  = df.text.apply(clean_txt)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stratified train val test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(df,stratify=df.label, test_size=0.2)\n",
    "train, val = train_test_split(train,stratify=train.label, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reset indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train.reset_index(inplace=True)\n",
    "val.reset_index(inplace=True)\n",
    "test.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test['label'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am not an expert in NLP and I have little experience with it but as I keep up with research paper I know that BERT (https://arxiv.org/abs/1810.04805) was used a lot in the last years. Moreover, it can \"be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks\". This is exactly what I need for this task because for sure I will not scrape thausands of pages but only a small dataset.\n",
    "\n",
    "For sure there are other techniques that could perform better but BERT comes with Pytorch transformers which are simple to use and adapt for a specific task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bert data preparation\n",
    "This approach is based on :\n",
    "* https://www.analyticsvidhya.com/blog/2020/07/transfer-learning-for-nlp-fine-tuning-bert-for-text-classification/#:~:text=%E2%80%9CBERT%20stands%20for%20Bidirectional%20Encoder,both%20left%20and%20right%20context\n",
    "* https://github.com/huggingface/transformers\n",
    "* https://medium.com/huggingface/multi-label-text-classification-using-bert-the-mighty-transformer-69714fa3fb3d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem with BERT is that it can fit only 510 tokens (much less than Wikipidia articles). Sun et al. (https://arxiv.org/abs/1905.05583) looked into this problem (text classification with larger text). There are different possibilities for truncation:\n",
    "* Cut at the beggining and at the end (head+tail)\n",
    "* Cut at the beginning (head only)\n",
    "* Cut at the end (tail only)\n",
    "\n",
    "In their experiments they proved that the head+tail truncation is the best option. Moreover they showed that simple tecniques (e.g. head only, tail only) outperform smarter methods like hierarchy mean and max (classification of different chunks and then an aggregation with max or mean pooling). \n",
    "\n",
    "As in this assiment I do not need a perfect model I will go with an **head only truncation** which is pretty simple to do and also effective. In an additional phase this model could be changed to try to improve the classification performance (e.g. perform text summarization before feeding it to BERT, chunk classification and vooting system, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the BERT tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased',do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_train = tokenizer.batch_encode_plus(train['text'].tolist(),truncation=True,padding=True)\n",
    "tokens_val = tokenizer.batch_encode_plus(val['text'].tolist(),truncation=True,padding=True)\n",
    "tokens_test = tokenizer.batch_encode_plus(test['text'].tolist(),truncation=True,padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokens_train[0].tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seq = torch.tensor(tokens_train['input_ids'])\n",
    "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
    "train_y = torch.tensor(train['label'].tolist())\n",
    "\n",
    "val_seq = torch.tensor(tokens_val['input_ids'])\n",
    "val_mask = torch.tensor(tokens_val['attention_mask'])\n",
    "val_y = torch.tensor(val['label'].tolist())\n",
    "\n",
    "test_seq = torch.tensor(tokens_test['input_ids'])\n",
    "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
    "test_y = torch.tensor(test['label'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The batch size is set to 2 instead of 16 ore 32 (suggestion from original paper) \n",
    "# because Gooogle Colab GPU cannot fit bigger batches \n",
    "#(if a more performant GPU is avialable it should be good to use 16 or 32).\n",
    "\n",
    "batch_size = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrap tensors\n",
    "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
    "\n",
    "# sampler for sampling the data during training\n",
    "train_sampler = RandomSampler(train_data)\n",
    "\n",
    "# dataLoader for train set\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrap tensors\n",
    "val_data = TensorDataset(val_seq, val_mask, val_y)\n",
    "\n",
    "# sampler for sampling the data during training\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "\n",
    "# dataLoader for validation set\n",
    "val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrap tensors\n",
    "test_data = TensorDataset(test_seq, test_mask, test_y)\n",
    "\n",
    "# sampler for sampling the data during training\n",
    "test_sampler = SequentialSampler(test_data)\n",
    "\n",
    "# dataLoader for test set\n",
    "test_dataloader = DataLoader(test_data, sampler = test_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering & Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the normal BERT model with an extra single linear layer on top for classification that we will use as a sentence classifier (https://huggingface.co/transformers/model_doc/bert.html#transformers.BertForSequenceClassification)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the corret number fo classes for the classification (in this case 10 output categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\", \n",
    "    num_labels = 10,   \n",
    "    output_attentions = False, \n",
    "    output_hidden_states = False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check output layers\n",
    "params = list(model.named_parameters())\n",
    "\n",
    "for p in params[-4:]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizer, in the original paper they propose to use one of these lr for fine-tuning learning (5e-5, 4e-5, 3e-5, and 2e-5) and as I do not have time for an hyperparameter search I will use 2e-5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr = 2e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As I scrape wikipedia to have balanced classes we do not need class weights, if that was the case sklearn.utils.class_weight can help a lot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training and evaluation loop based on https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dataloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-e6826a9bfa7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Total number of training steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtotal_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Scheduler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_dataloader' is not defined"
     ]
    }
   ],
   "source": [
    "# Number of training epochs (authors recommend between 2 and 4). To see how it behave and because it is pretty fast to\n",
    "# train on a GPU I decided to use more epochs (only the model which achieves the highest val accuracy is kept).\n",
    "epochs = 10\n",
    "\n",
    "# Total number of training steps\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Scheduler\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0,\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_time(elapsed):\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    #  hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader):\n",
    "    print(\"Training...\")\n",
    "    \n",
    "    # Start time\n",
    "    t0 = time.time()\n",
    "\n",
    "    total_loss = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for step, batch in enumerate(dataloader):\n",
    "\n",
    "        # Progress update every 40 batches.\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            # Elapsed time in mins\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        \n",
    "        batch = [r.to(device) for r in batch]\n",
    "        sent_id, mask, labels = batch\n",
    "\n",
    "        # Clear gradients\n",
    "        model.zero_grad()        \n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(sent_id,\n",
    "                    attention_mask=mask, \n",
    "                    labels=labels,\n",
    "                    return_dict=True)\n",
    "        \n",
    "        # Get loss on CrossEntropyLoss\n",
    "        loss = outputs.loss\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the the gradients to 1.0 (exploding gradient)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update lr\n",
    "        scheduler.step()\n",
    "\n",
    "    # average loss\n",
    "    avg_train_loss = total_loss / len(train_dataloader)            \n",
    "    \n",
    "\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
    "    \n",
    "    return avg_train_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataloader):\n",
    "    print(\"Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "    \n",
    "    total_loss = 0\n",
    "\n",
    "    # Eval mode\n",
    "    model.eval()\n",
    "\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    predictions , true_labels = [], []\n",
    "\n",
    "    for batch in dataloader:\n",
    "        \n",
    "        batch = [r.to(device) for r in batch]\n",
    "        sent_id, mask, labels = batch\n",
    "        \n",
    "        with torch.no_grad():        \n",
    "            outputs = model(sent_id, \n",
    "                            attention_mask=mask,\n",
    "                            labels=labels,\n",
    "                               return_dict=True)\n",
    "        \n",
    "        # Logits (before softmax) \n",
    "        logits = outputs.logits\n",
    "        \n",
    "        # Get loss on CrossEntropyLoss\n",
    "        loss = outputs.loss\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # Put values to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = labels.to('cpu').numpy()\n",
    "        \n",
    "        # Predictions and true labels\n",
    "        predictions.extend(logits)\n",
    "        true_labels.extend(label_ids)\n",
    "        \n",
    "        # Accumulate the total accuracy.\n",
    "        eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "\n",
    "    \n",
    "    # Average loss\n",
    "    avg_val_loss = total_loss / len(dataloader)            \n",
    "    \n",
    "    # Average accuracy\n",
    "    avg_val_accuracy = eval_accuracy/len(dataloader)\n",
    "    \n",
    "    \n",
    "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
    "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
    "    \n",
    "    return avg_val_loss, avg_val_accuracy, predictions, true_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_values = []\n",
    "loss_val_values = []\n",
    "accuracy_val_val = 0.0\n",
    "for epoch in range(0, epochs):\n",
    "    \n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch + 1, epochs))\n",
    "    \n",
    "    # Train\n",
    "    avg_train_loss = train(train_dataloader)\n",
    "    loss_values.append(avg_train_loss)\n",
    "    \n",
    "        \n",
    "    # Validation\n",
    "    avg_val_loss, avg_val_accuracy, _, _ = evaluate(val_dataloader)\n",
    "    loss_val_values.append(avg_val_loss)\n",
    "    accuracy_val_values.append(avg_val_accuracy)\n",
    "    \n",
    "    # Save best model\n",
    "    if avg_val_accuracy > best_val_acc:\n",
    "        best_val_acc = avg_val_accuracy\n",
    "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
    "\n",
    "print(\"Done\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results & Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot loss and accuracy of the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use plot styling from seaborn.\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "# Increase the plot size and font size.\n",
    "sns.set(font_scale=1.5)\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "\n",
    "# Plot the learning curve.\n",
    "plt.plot(loss_values, 'b-o')\n",
    "\n",
    "# Label the plot.\n",
    "plt.title(\"Training loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the learning curve.\n",
    "plt.plot(loss_val_values, 'b-o')\n",
    "\n",
    "# Label the plot.\n",
    "plt.title(\"Validation loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the learning curve.\n",
    "plt.plot(accuracy_val_values, 'b-o')\n",
    "\n",
    "# Label the plot.\n",
    "plt.title(\"Validation accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like the network cannot get better than 91% accuracy (probably it should be better to look at other metrics). Moreover, it starts to overfit after 2 epochs. Maybe with a smaller/bigger learning rate the network could get better but as the objective is not to get best performance I will leave it like that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_, _, predictions, true_labels = evaluate(test_dataloader)\n",
    "preds = np.argmax(predictions, axis = 2)\n",
    "print(classification_report(true_labels, preds, target_names=list(label_encoder.classes_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the classification report on a test set, we can see that also the other metrics (i.e. precision, recal and f1) follow the accuracy. In this case, the accuracy is not as high as the validation set (91%) but at a 86%. For the given small dataset I think this is a pretty good result. \n",
    "\n",
    "Probably with an hyperparameters search and maybe an higher batch size (batch size seems to have always an inpact on training), which in this case was 2 (for GPU memory limitation), the model could achieve better performance. I read different papers about that but I cannot find them... I am not sure if this assumption is also true for BERT.\n",
    "\n",
    "The classification report shows the macro average (averaging the unweighted mean per label), weighted average (averaging the support-weighted mean per label).\n",
    "\n",
    "\n",
    "If we look more into the precision and accuracy of the different classes we can see that this model have some problems especially with **culture** and **philosophy**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(true_labels, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = mlxtend.plotting.plot_confusion_matrix(conf_mat=cm,\n",
    "                                colorbar=False,\n",
    "                                show_absolute=True,\n",
    "                                show_normed=True,\n",
    "                                figsize=(10, 10)\n",
    "                                class_names=list(label_encoder.classes_))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
